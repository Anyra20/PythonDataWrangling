{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Data Wrangling with Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<ul>    \n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#gather\">Gather</a></li>\n",
    "<li><a href=\"#assess\">Assess</a></li>\n",
    "<li><a href=\"#clean\">Clean</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "<li><a href=\"#ref\">References</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "In this project I'm going to analyze the dataset from twitter account WeRateDogsÂ®\n",
    "<br>\n",
    "using Tweepy to query Twitter's API for additional data: retweet count and favorite count\n",
    "<br>\n",
    "Assessing data\n",
    "Cleaning data\n",
    "Storing, analyzing, and visualizing your wrangled data\n",
    "Reporting on 1) your data wrangling efforts and 2) your data analyses and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "## Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import requests \n",
    "import os\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive = pd.read_csv(\"twitter-archive-enhanced.csv\")\n",
    "df_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image predictions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), url.split('/')[-1]), mode='wb') as file:\n",
    "          file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.read_csv('image-predictions.tsv', sep='\\t')\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweepy\n",
    "create an API object to gather Twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = '7GCntbM7icOGMHkkXjcQXfTkL'\n",
    "consumer_secret = 'gZP0QgAihs5EoDZFi6PdfwkDfill046cWS1fRZajz84mgVgpxB'\n",
    "access_token = '960852542-Q9H69Zz43N7xvQEAEY25il9Xl5P3ZAjVnfzc2HEe'\n",
    "access_secret = 'xM4iTrao32Su1Ww2ygacFoZtfTBGpzGz0u5uEZLmqsMcl'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from Twitter\n",
    "id_list = df.tweet_id.astype(str)#[0:10]\n",
    "tweets = []\n",
    "error_count = 0\n",
    "error_ids = []\n",
    "for tweet_id in id_list:\n",
    "    try:\n",
    "        tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        tweets.append(tweet._json)\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e)\n",
    "        error_ids.append(tweet_id)\n",
    "error_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_ids = ['888202515573088257','873697596434513921','872668790621863937','872261713294495745', '869988702071779329','866816280283807744','861769973181624320','856602993587888130','851953902622658560','845459076796616705','844704788403113984','842892208864923648','837366284874571778',\n",
    " '837012587749474308','829374341691346946','827228250799742977','812747805718642688','802247111496568832','779123168116150273','775096608509886464','771004394259247104', '770743923962707968','759566828574212096','754011816964026368','680055455951884288']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write json data to file\n",
    "with open('tweet_json.txt', 'w') as file:\n",
    "    json.dump(tweets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read json data from file\n",
    "ls_tweets = []\n",
    "with open('tweet_json.txt') as file:\n",
    "    data = json.load(file)\n",
    "    for p in data:\n",
    "        ls_tweets.append({'tweet_id': p['id'],\n",
    "                        'retweet_count': p['retweet_count'],\n",
    "                        'favorite_count': p['favorite_count']})\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ls_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataFrame from list \n",
    "df_tweets = pd.DataFrame(ls_tweets, columns = ['tweet_id', 'retweet_count', 'favorite_count'])\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.tweet_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #full_tweets = []\n",
    "   # tweet_count = df.tweet_id.count()\n",
    "  #  id_list = df.tweet_id.astype(str)\n",
    "  #  try:\n",
    "   #     for i in range(int(tweet_count / 100) + 1):\n",
    "   #         end_loc = min((i + 1) * 100, tweet_count)\n",
    "            #print(id_list[i * 100:end_loc])\n",
    "  #          list100 = id_list.iloc[(i * 100):end_loc]\n",
    "   #         full_tweets.extend(api.statuses_lookup(list100))\n",
    "  #          print(str(i))\n",
    "  #          if i>5: break\n",
    "  #  except tweepy.TweepError as e:\n",
    "  #      print('Error:', e.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Archive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Detect and document at least eight (8) quality issues and two (2) tidiness issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.query('in_reply_to_status_id !=\"NaN\" and in_reply_to_user_id !=\"NaN\"').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.query('retweeted_status_id !=\"NaN\" and retweeted_status_user_id !=\"NaN\"').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues\n",
    "##### df_ archive table\n",
    "Original records have these columns equal NaN<br>\n",
    "- in_reply_to_status_id<br>\n",
    "- in_reply_to_user_id<br>\n",
    "- retweeted_status_id<br>\n",
    "- retweeted_status_user_id<br>\n",
    "- retweeted_status_timestamp<br>\n",
    "<br>\n",
    "\n",
    "Columns to delete: *timestamp, source, expanded_urls* <br>\n",
    "\n",
    "*rating_denominator* has some incorrect data, zeros, big numbers (decimal?)<br>\n",
    "*rating_numerator* can be decimal like 13.5/10 tweet_id:883482846933004288<br>\n",
    "Some records have *rating_numerator* = 0 or >20<br>\n",
    "*name* columns has some errors like name 'None' or 'a'. I'm not sure it will be used for analysis<br>\n",
    "\n",
    "*doggo, floofer, pupper, puppo* columns have values only in 380 records vs 430 in *text* column\n",
    "*doggo, floofer, pupper, puppo* can be combined in one column<br>\n",
    "*tweet_id* as object type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicated data\n",
    "df_archive[df_archive.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_denominator'].describe()\n",
    "# rating_numerator rating_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive[df_archive['rating_denominator'] !=10][['tweet_id', 'rating_denominator', 'rating_denominator', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['rating_numerator'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.query('rating_numerator < 1 or rating_numerator > 20')[['tweet_id', 'rating_numerator', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.query(\"doggo != 'None' or floofer != 'None' or pupper != 'None' or puppo != 'None'\").shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive[df_archive['text'].str.contains(\"puppo\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive[df_archive['text'].str.contains(\"floof\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive[df_archive['text'].str.contains(\"pupper\")].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image prediction table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues\n",
    "##### df_predictions table\n",
    "\n",
    "*jpg_url* column do not needed <br>\n",
    "*p1, p2, p3* some breeds start with capital letter, some not<br>\n",
    "Missing data: there are no predictions for 281 records from archive table (replies and retweets???)\n",
    "*tweet_id* as object type not int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.img_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_predictions.p1_conf.describe()\n",
    "#df_predictions.p2_conf.describe()\n",
    "df_predictions.p3_conf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_predictions.p1.value_counts()\n",
    "#df_predictions.p2.value_counts()\n",
    "df_predictions.p3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweets in archive table and not in prediction table\n",
    "len(list(set(df.tweet_id) - set(df_predictions.tweet_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(df_predictions.tweet_id) - set(df.tweet_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweepy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.retweet_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets.query('retweet_count < 5 or retweet_count > 70000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.favorite_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets[df_tweets.favorite_count == 0] df_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Issues\n",
    "##### df_tweets table\n",
    "- Merge df_tweets and df_archive table. df_tweets is just additional info about the same tweets <br>\n",
    "- Some tweets were deleted, df_tweets has no info about them, ids in error_ids list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaning includes merging individual pieces of data according to the rules of tidy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define Code Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Storing, Analyzing, and Visualizing Data for this Project\n",
    "Store the clean DataFrame(s) in a CSV file with the main one named twitter_archive_master.csv. If additional files exist because multiple tables are required for tidiness, name these files appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "At least three (3) insights and one (1) visualization must be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/28384588/twitter-api-get-tweets-with-specific-id\n",
    "<br>\n",
    "https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/\n",
    "<br>\n",
    "https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
